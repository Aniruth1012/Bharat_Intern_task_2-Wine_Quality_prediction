# -*- coding: utf-8 -*-
"""Untitled61.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jDXHCOsAvQOWWKAXm_WAAmhUDJ-0-Nct

Importing the Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""Importing the dataset"""

dataset=pd.read_csv('WineQuality.csv')

"""Deriving Variables based on mi scores and dataset content"""

dataset['fvratio']=dataset['fixed acidity']/dataset['volatile acidity']
shift=dataset.pop('fvratio')
dataset.insert(2, 'fvratio', shift)
dataset['ftratio']=dataset['free sulfur dioxide']/dataset['total sulfur dioxide']
shift1=dataset.pop('ftratio')
dataset.insert(2, 'ftratio', shift1)
dataset['csratio']=dataset['chlorides']/dataset['sulphates']
shift2=dataset.pop('csratio')
dataset.insert(2, 'csratio', shift2)
shift3=dataset.pop('Type')
dataset.insert(3,'Type',shift3)

"""Seperating the Dependent and Independent Variables"""

X=dataset.iloc[:,1:-1].values
Y=dataset.iloc[:,-1].values

"""Cross Checking the dataset by printing header"""

print(dataset.head())

"""Check for Missing values"""

if dataset.isnull().any().any():
  print('true')

"""Handling Missing values"""

rows_with_nan = dataset[dataset.isnull().any(axis=1)]
print(rows_with_nan)

#Since rows with Nan values are comparitively less we shall proceed by removing those
dataset = dataset.dropna()

if dataset.isnull().any().any():
  print('true')

"""Encoding the Cateogrical Variables"""

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
X[:,2]=le.fit_transform(X[:,2])

"""Feature Engineering to find mi score of variables"""

from sklearn.feature_selection import mutual_info_regression
mi_scores = mutual_info_regression(X,Y)
feature_names=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']
feature_mi_scores = list(zip(feature_names, mi_scores))
feature_mi_scores.sort(key=lambda x: x[1], reverse=True)

print(feature_mi_scores)

"""NOTE : Variables derived at the start were using the mi scores

Splitting into training and test set
"""

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=0)

"""Feature Scaling"""

from sklearn.preprocessing import StandardScaler
sc_x=StandardScaler()
sc_y=StandardScaler()
X_train=sc_x.fit_transform(X_train)
Y_train=sc_y.fit_transform(Y_train.reshape(-1,1))

"""Training the Random Forest Model on training set"""

from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(n_estimators = 500, random_state = 0)
regressor.fit(X_train,Y_train)

"""NOTE : Random Forest provides best results after trying with other regression models

Predicting the Test set
"""

Y_pred=sc_y.inverse_transform(regressor.predict(sc_x.transform(X_test)).reshape(-1,1))

print(Y_pred.reshape(1,-1))

print(Y_test)

"""Testing the score of the model"""

from sklearn.metrics import r2_score
r2_score(Y_test,Y_pred.reshape(-1,1))